## 	LRU与LFU

缓存是一个计算机思维，对于重复的计算，缓存其结果，下次再算这个任务的时候，不去真正的计算，而是直接返回结果，能加快处理速度。当然有些会随时间改变的东西，缓存会失效，得重新计算。

比如缓存空间只有2个，要缓存的数据有很多，1，2，3，4，5，那么当缓存空间满了，需要淘汰一个缓存出去，其中淘汰算法有 LRU，LFU，FIFO，SC二次机会，老化算法，时钟工作集算法等等。

### 算法流程

**LRU（最近最少使用）**：把数据加入一个链表中，按访问时间排序，发生淘汰的时候，把访问时间最旧的淘汰掉。

 比如有数据 1，2，1，3，2，此时缓存中已有（1，2）， 当3加入的时候，得把后面的2淘汰，变成（3，1）

**LFU（最近不经常使用**）：把数据加入到链表中，按频次排序，一个数据被访问过，把它的频次+1，发生淘汰的时候，把频次低的淘汰掉。
 比如有数据 1，1，1，2，2，3，缓存中有（1(3次)，2(2次)）， 当3加入的时候，得把后面的2淘汰，变成（1(3次)，3(1次)）

### 区别：

**1.LRU淘汰根据访问时间前后，LFU淘汰根据出现频率高低**

**2.LRU对于循环出现的数据，缓存命中不高**

​	比如，这样的数据，1，1，1，2，2，2，3，4，1，1，1，2，2，2.....

​	当走到3，4的时候，1，2会被淘汰掉，但是后面还有很多1，2

**3.LFU对于交替出现的数据，缓存命中不高**

​	比如，1，1，1，2，2，3，4，3，4，3，4，3，4，3，4，3，4......

​	由于频次为：{1:3次，2:2次}，3加入把2淘汰，4加入把3淘汰，3加入把4淘汰，然而3，4才是最需要缓存的，1去到了3次，谁也淘汰不了它了。

### 实现

**1.LRU的一个实现方法：**

 用一个双向链表记录访问时间，因为链表插入删除高效，时间新的在前面，旧的在后面。

用一个哈希表记录缓存(key, value)，哈希查找近似O(1)，发生哈希冲突时最坏O(n)，同时哈希表中得记录 (key, (value, key_ptr))，key_ptr 是key在链表中的地址，为了能在O(1)时间内找到该节点，并把节点提升到表头。

链表中的key，能快速找到hash中的value，并删除。

**2.LFU的一个实现方法：**

用一个主双向链表记录（访问次数，从链表头），从链表中按时间顺序记录着（key）

 用一个哈希表记录（key，(value, 主链表ptr，从链表ptr)）ptr表示该key在链表中的地址
 然后，get，put都在哈希表中操作，近似O(1)，哈希表中有个节点在链表中的地址，能O(1)找到，并把节点提搞访问频次，链表插入删除也都是O(1)。